{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857bc948",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family: 'Constantia'; font-size: 26px; color:#006400;\"> 1 üîé Setting The Scene üîé\n",
    "<p style=\"color:  #93E9BE; font-family: 'Constantia', cursive;\"> üå≥Preliminary exploration using Isolation Forest and Hypothesis Testingüå≥</p></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ccdd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from missingno) (3.5.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from missingno) (0.11.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from missingno) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from missingno) (1.21.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (3.0.9)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from seaborn->missingno) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn->missingno) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# importing dependencies \n",
    "\n",
    "# !pip install ydata-profiling \n",
    "#installing the library\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "!pip install missingno "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd03930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno # great library for visualisating the distribution of nulls!\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Hypothesis Testing\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, BayesianRidge, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Other\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import re\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c5fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0 Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3bfffc",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Why should we be interested in</span> <span style=\"color:red; font-family:'Segoe Script', cursive;\">legendary</span> <span style=\"color:green; font-family:'Comic Sans MS', cursive;\">pokemon</span>? üåüüî•üåà"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456ec44",
   "metadata": {},
   "source": [
    "<img src=\"https://media.tenor.com/u-qWcV0GwbkAAAAC/mew-pokemon.gif\" alt=\"Legendary Pokemon Mew\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac784f9",
   "metadata": {},
   "source": [
    "As most Pokemon enthusiasts would know, legendary Pokemon are rare creatures that have exceptional power, abilties and base stats. They often play a key role in the Pokemon storyline and mythology. Acquiring one has long been an attractive challenge to players as they can have a major impact on battle strategies and outcomes. Legendary Pokemon also look pretty cool :P "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5142572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d05ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('pokemon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() #fortunately, the names of the data have been standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24196225",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc[1]) #sample row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44471a",
   "metadata": {},
   "source": [
    "For the sake of logical flow and structure, I have decided to put this part first, preceding all other parts of the project, in order to provide a persuasive reason as to why this project is being undertaken in the first place. As such, I will be using a version of the same dataset that has been partially cleaned. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ce811",
   "metadata": {},
   "source": [
    "**Are legendary pokemon truly rarer and more anomalous than non-legendary pokemon?** To find out, we can use a combination of **Anomaly Testing(Isolation Forest)** and using the results thereafter to conduct a **two sample hypothesis test**.  To determine the true **direction** of the anomaly (do legendary pokemon have exceptionally **better** or exceptionally **crappier** stats than non-legendary pokemon?), we would have to look at our **Tableau Visaulisations!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f577294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rarity_data = pd.read_csv('pokemon_partially_cleaned.csv')\n",
    "rarity_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99563d92",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green; font-family:Comic Sans MS;\">üå≥ Isolation Forest Model üå≥</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b5de7",
   "metadata": {},
   "source": [
    "### The isolation forest model is an unsupervised learning model that isolates anomalies or rare occurences within the data by creating a set of random decision trees which split into two. Anomalies can be identified with fewer splits, which means the average path length to its branch is shorter than average (which is why anomaly scores are negative in value). More information [here](https://www.analyticsvidhya.com/blog/2021/07/anomaly-detection-using-isolation-forest-a-complete-guide/) and [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e072f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the variables before training the IsolationForest model\n",
    "\n",
    "predictor_variables = rarity_data.drop(columns=['name','japanese_name','abilities', 'base_egg_steps'])  # 'is_legendary' is the target variable\n",
    "\n",
    "# Step 2: Drop the 'type1_' and 'type2_' variables\n",
    "type1_columns = [col for col in predictor_variables.columns if col.startswith('type1_')]\n",
    "type2_columns = [col for col in predictor_variables.columns if col.startswith('type2_')]\n",
    "predictor_variables = predictor_variables.drop(columns=type1_columns + type2_columns)\n",
    "selected_rarity_features = ['hp', 'attack', 'defense', 'sp_attack', 'sp_defense', 'speed']\n",
    "\n",
    "# Create a new DataFrame containing only the selected features\n",
    "rarity_features_df = predictor_variables[selected_rarity_features].copy()\n",
    "\n",
    "# Normalize the features (optional but can improve performance)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(rarity_features_df)\n",
    "features_df = pd.DataFrame(scaled_features, columns=selected_rarity_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352544e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the IsolationForest class\n",
    "isolation_forest = IsolationForest(contamination=0.001)  # Adjust contamination based on expected rarity proportion\n",
    "\n",
    "# Fit the model on the features\n",
    "isolation_forest.fit(features_df)\n",
    "\n",
    "# Predict the anomaly scores for each Pok√©mon (negative values indicate anomalies)\n",
    "anomaly_scores = isolation_forest.score_samples(features_df)\n",
    "\n",
    "# Add the anomaly scores to the original DataFrame\n",
    "rarity_data['AnomalyScore'] = anomaly_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb673c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of anomaly scores - the lower the anomaly score, the rarer the pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4369e5de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(rarity_data['AnomalyScore'], bins=20, kde=True)\n",
    "plt.title('Distribution of Anomaly Scores')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "rare_pokemon = rarity_data.nsmallest(10, 'AnomalyScore') #lists the top ten most anomalous/rarest/most unique pokemon in the dataset\n",
    "print(rare_pokemon[['name', 'AnomalyScore']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47360656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 of the most anomalous pokemon are legendary pokemon! But we'll have to tune the model to really know for sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "legendary_pokemon = rare_pokemon[rare_pokemon['is_legendary'] == 1]\n",
    "\n",
    "# Print the names and AnomalyScores of legendary Pok√©mon\n",
    "print(legendary_pokemon[['name', 'AnomalyScore']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf89ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning via GridCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolation_forest = IsolationForest()\n",
    "\n",
    "# Defining the model's hyperparameters and their values so that they can be tuned\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],    # Number of trees in the forest\n",
    "    'max_samples': [0.1, 0.2, 0.3],    # Proportion of samples to draw for each tree\n",
    "    'contamination': [0.01, 0.05, 0.1] # Expected proportion of anomalies (rare Pok√©mon)\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the Isolation Forest model and parameter grid\n",
    "grid_search = GridSearchCV(isolation_forest, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV object on the features\n",
    "grid_search.fit(features_df)\n",
    "\n",
    "# Get the best hyperparameters from the search\n",
    "best_hyperparameters = grid_search.best_params_\n",
    "\n",
    "# Create a new Isolation Forest model with the best hyperparameters\n",
    "best_isolation_forest = IsolationForest(**best_hyperparameters)\n",
    "\n",
    "# Fit the best model on the features\n",
    "best_isolation_forest.fit(features_df)\n",
    "\n",
    "# Predict the anomaly scores for each Pok√©mon using the best model\n",
    "anomaly_scores = best_isolation_forest.score_samples(features_df)\n",
    "\n",
    "# Add the anomaly scores to the original DataFrame\n",
    "rarity_data['AnomalyScore'] = anomaly_scores\n",
    "\n",
    "# Sort the DataFrame by 'AnomalyScore' in ascending order\n",
    "rarity_data_sorted = rarity_data.sort_values(by='AnomalyScore', ascending=True)\n",
    "\n",
    "# Get the top ten rarest Pok√©mon\n",
    "top_rarest_pokemon = rarity_data_sorted.head(10)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hyperparameters)\n",
    "\n",
    "# Print the top ten rarest Pok√©mon\n",
    "print(\"\\nTop Ten Rarest Pok√©mon:\")\n",
    "print(top_rarest_pokemon[['name', 'AnomalyScore']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baeb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of anomaly scores\n",
    "sns.histplot(rarity_data['AnomalyScore'], bins=20, kde=True)\n",
    "plt.title('Distribution of Anomaly Scores')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ebb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After tuning the hyperparameters of the Isolation Forest Model, only two legendary pokemon remain in the top ten. How about the rest of the 70 pokemon in general?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c80712",
   "metadata": {},
   "outputs": [],
   "source": [
    "legendary_pokemon1 = top_rarest_pokemon[top_rarest_pokemon['is_legendary'] == 1]\n",
    "print(legendary_pokemon1[['name', 'AnomalyScore']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the filtered data below, we can see that all 70 pokemon are in the top 500 in terms of anomaly scores. But we'll need more concrete proof to irrevocably conlcude that legendary pokemon are indeed rarer and more anomalous than non-legendary pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9591e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "legendary_data = rarity_data[rarity_data['is_legendary'] == 1]\n",
    "\n",
    "# Applying a filter \n",
    "non_legendary_data = rarity_data[rarity_data['is_legendary'] == 0]\n",
    "\n",
    "# Concatenating both legendary and non-legendary Pok√©mon data\n",
    "all_data = pd.concat([legendary_data, non_legendary_data])\n",
    "\n",
    "# Adding a new 'rank' column\n",
    "all_data = all_data.sort_values(by='AnomalyScore', ascending=True)\n",
    "all_data['Rank'] = range(1, len(all_data) + 1)\n",
    "\n",
    "# Let's print it!\n",
    "legendary_data_filtered = all_data[all_data['is_legendary'] == 1]\n",
    "print(legendary_data_filtered[['name', 'AnomalyScore', 'Rank']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4538f0",
   "metadata": {},
   "source": [
    "**Now, we can proceed with hypothesis testing using the anomaly scores that have been just generated.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a20e7",
   "metadata": {},
   "source": [
    "<h3 style=\"color: blue; font-family: 'Courier New';\">‚ù§Ô∏è Hypothesis testing for two-tailed t-test ‚ù§Ô∏è</h3>\n",
    "\n",
    "\n",
    "#### **(H<sub>0</sub>): Legendary pokemon are not rarer and more anomalous then non-legendary pokemon.**\n",
    "\n",
    "#### **(H<sub>1</sub>): Legendary pokemon are rarer and more anomalous than non-legendary pokemon.**\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the AnomalyScores for legendary and non-legendary Pok√©mon\n",
    "legendary_scores = legendary_data['AnomalyScore']\n",
    "non_legendary_scores = non_legendary_data['AnomalyScore']\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_stat, p_value = ttest_ind(legendary_scores, non_legendary_scores, equal_var=False)\n",
    "\n",
    "alpha = 0.01  # Choosing a conservative alpha\n",
    "if p_value < alpha:\n",
    "    print(\"\\033[1;31mThe difference in AnomalyScores between legendary and non-legendary Pok√©mon is statistically significant.\\033[0m Thus, Legendary Pok√©mon are rarer and more anomalous than non-legendary Pok√©mon.\")\n",
    "else:\n",
    "    print(\"\\033[1;32mThere is no significant difference in AnomalyScores between legendary and non-legendary Pok√©mon.\\033[0m Thus, we cannot \\033[1;32mreject the null hypothesis\\033[0m and conclude that \\033[1;32mLegendary Pok√©mon are not rarer and more anomalous than non-legendary Pok√©mon.\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ace522",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial, sans-serif; font-size: 24px;\">To confirm the direction of anomalousness</span> <span style=\"font-family: 'Chewy', cursive; color: red; font-size: 24px;\">(are legendary Pok√©mon anomalously better or crappier)</span><span style=\"font-family: 'Chewy', cursive; color: linear-gradient(to right, violet, indigo, blue, green, yellow, orange, red); font-size: 24px;\">, please proceed to my Tableau visualizations for the rest of the EDA! üåà</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d256c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
